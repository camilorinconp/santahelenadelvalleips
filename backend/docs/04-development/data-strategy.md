# ðŸ’¾ Estrategia de Datos Enterprise

**ðŸ“… Fecha:** 16 septiembre 2025  
**ðŸŽ¯ Audiencia:** Database Engineers, Data Architects, Backend Developers  
**ðŸ“Š Complejidad:** Alta  
**âš¡ Impacto:** CrÃ­tico (performance y compliance)

---

## ðŸŽ¯ **ESTRATEGIA DE TIPADO EN 3 CAPAS**

### **ðŸ—ï¸ FilosofÃ­a: "El Tipo Correcto para el Contexto Correcto"**

```
CAPA 1: ESTRUCTURADA (ENUMs + Tablas CatÃ¡logo)
â”œâ”€â”€ Datos pequeÃ±os, estables, fijos
â”œâ”€â”€ ValidaciÃ³n automÃ¡tica BD nivel
â””â”€â”€ Performance Ã³ptima joins

CAPA 2: SEMI-ESTRUCTURADA (JSONB)  
â”œâ”€â”€ Datos flexibles, variabilidad alta
â”œâ”€â”€ Queries complejas con Ã­ndices GIN
â””â”€â”€ EvoluciÃ³n sin migrations

CAPA 3: NO ESTRUCTURADA (TEXT)
â”œâ”€â”€ Narrativas mÃ©dicas, observaciones
â”œâ”€â”€ Contenido para IA/RAG futuro
â””â”€â”€ Full-text search optimizado
```

### **ðŸ“Š Ejemplo ImplementaciÃ³n por Capas**

#### **ðŸ”¹ CAPA 1: ENUMs + CatÃ¡logos**
```sql
-- ENUMs para valores pequeÃ±os y estables
CREATE TYPE estado_nutricional_infancia AS ENUM (
    'NORMAL', 'DELGADEZ', 'SOBREPESO', 'OBESIDAD', 'TALLA_BAJA'
);

-- Tabla catÃ¡logo para datos grandes/dinÃ¡micos
CREATE TABLE catalogo_ocupaciones_dane (
    id UUID PRIMARY KEY,
    codigo_dane TEXT UNIQUE NOT NULL,
    denominacion TEXT NOT NULL,
    descripcion_funciones TEXT,
    nivel_formacion_requerido TEXT,
    activo BOOLEAN DEFAULT true,
    fecha_vigencia DATE,
    metadata JSONB  -- Datos adicionales flexibles
);

CREATE INDEX idx_ocupaciones_codigo ON catalogo_ocupaciones_dane(codigo_dane);
CREATE INDEX idx_ocupaciones_activo ON catalogo_ocupaciones_dane(activo) WHERE activo = true;
```

#### **ðŸ”¹ CAPA 2: JSONB Semi-Estructurado**
```sql
-- Datos complejos con variabilidad
CREATE TABLE atencion_infancia (
    id UUID PRIMARY KEY,
    -- Campos estructurados crÃ­ticos
    peso_kg DECIMAL(5,2) NOT NULL,
    talla_cm DECIMAL(5,2) NOT NULL,
    
    -- JSONB para datos semi-estructurados
    factores_riesgo_contextuales JSONB,
    datos_desarrollo_psicomotor JSONB,
    alertas_automaticas_detectadas JSONB
);

-- Ãndices GIN para queries JSONB eficientes
CREATE INDEX idx_factores_riesgo_gin ON atencion_infancia USING GIN(factores_riesgo_contextuales);
CREATE INDEX idx_alertas_gin ON atencion_infancia USING GIN(alertas_automaticas_detectadas);

-- Queries JSONB optimizadas
SELECT * FROM atencion_infancia 
WHERE factores_riesgo_contextuales @> '{"sedentarismo": true}';
```

#### **ðŸ”¹ CAPA 3: TEXT No Estructurado**
```sql
-- Contenido narrativo para IA/RAG
CREATE TABLE atencion_infancia (
    id UUID PRIMARY KEY,
    -- Narrativas mÃ©dicas profesionales
    observaciones_desarrollo_cognitivo TEXT,
    recomendaciones_profesional_infancia TEXT,
    antecedentes_familiares_relevantes TEXT,
    
    -- Ãndices full-text search
    observaciones_search_vector tsvector GENERATED ALWAYS AS (
        to_tsvector('spanish', 
            COALESCE(observaciones_desarrollo_cognitivo, '') || ' ' ||
            COALESCE(recomendaciones_profesional_infancia, '')
        )
    ) STORED
);

CREATE INDEX idx_observaciones_fts ON atencion_infancia USING GIN(observaciones_search_vector);
```

---

## ðŸ—ï¸ **POLIMORFISMO CON CONSTRAINTS DE INTEGRIDAD**

### **ðŸ”„ PatrÃ³n 3 Pasos PolimÃ³rfico**
```python
# ImplementaciÃ³n Python del patrÃ³n polimÃ³rfico
async def crear_atencion_polimorfica(atencion_data, db):
    """
    PASO 1: Crear detalle especÃ­fico SIN referencia atenciÃ³n general
    PASO 2: Crear atenciÃ³n general que referencie al detalle  
    PASO 3: Actualizar detalle con referencia bidireccional
    """
    
    try:
        # PASO 1: Crear detalle especÃ­fico (ej: infancia)
        detalle_dict = atencion_data.model_dump()
        detalle_dict['id'] = str(uuid4())
        # âŒ NO incluir atencion_id todavÃ­a
        
        detalle_response = db.table("atencion_infancia").insert(detalle_dict).execute()
        detalle_id = detalle_response.data[0]['id']
        
        # PASO 2: Crear atenciÃ³n general
        atencion_general = {
            "id": str(uuid4()),
            "paciente_id": str(atencion_data.paciente_id),
            "tipo_atencion": "AtenciÃ³n Infancia",
            "detalle_id": detalle_id,  # â† Referencia polimÃ³rfica
            "fecha_atencion": atencion_data.fecha_atencion.isoformat()
        }
        
        atencion_response = db.table("atenciones").insert(atencion_general).execute()
        atencion_id = atencion_response.data[0]['id']
        
        # PASO 3: Actualizar detalle con referencia bidireccional
        update_response = db.table("atencion_infancia")\
            .update({"atencion_id": atencion_id})\
            .eq("id", detalle_id).execute()
            
        return detalle_id, atencion_id
        
    except Exception as e:
        # Rollback automÃ¡tico en caso error
        await rollback_polimorfismo(detalle_id, atencion_id, db)
        raise HTTPException(status_code=500, detail=f"Error polimÃ³rfico: {str(e)}")
```

### **âš¡ Performance Optimization por Uso**
```sql
-- Ãndices especializados por patrÃ³n acceso
-- 1. Acceso por paciente (mÃ¡s frecuente)
CREATE INDEX idx_atenciones_paciente_fecha ON atenciones(paciente_id, fecha_atencion DESC);

-- 2. Acceso por tipo de atenciÃ³n  
CREATE INDEX idx_atenciones_tipo ON atenciones(tipo_atencion) 
WHERE tipo_atencion IN ('AtenciÃ³n Infancia', 'Control Cronicidad', 'Tamizaje OncolÃ³gico');

-- 3. Ãndice polimÃ³rfico para joins eficientes
CREATE INDEX idx_atenciones_detalle_tipo ON atenciones(detalle_id, tipo_atencion);

-- 4. Ãndices especializados por detalle
CREATE INDEX idx_infancia_atencion ON atencion_infancia(atencion_id) WHERE atencion_id IS NOT NULL;
CREATE INDEX idx_infancia_paciente_fecha ON atencion_infancia(paciente_id, fecha_atencion DESC);
```

---

## ðŸ“Š **DATABASE PERFORMANCE ENTERPRISE**

### **ðŸš€ OptimizaciÃ³n Query Performance**

#### **Query Patterns Optimizadas**
```sql
-- âŒ ANTI-PATTERN: N+1 Queries
SELECT * FROM atenciones WHERE paciente_id = $1;
-- Para cada atenciÃ³n:
SELECT * FROM atencion_infancia WHERE atencion_id = $2;

-- âœ… OPTIMIZED: Single Query con CTE
WITH atenciones_completas AS (
    SELECT 
        a.*,
        ai.*,
        p.primer_nombre || ' ' || p.primer_apellido AS nombre_completo
    FROM atenciones a
    LEFT JOIN atencion_infancia ai ON a.detalle_id = ai.id 
        AND a.tipo_atencion = 'AtenciÃ³n Infancia'
    JOIN pacientes p ON a.paciente_id = p.id
    WHERE a.paciente_id = $1
      AND a.fecha_atencion >= $2
)
SELECT * FROM atenciones_completas ORDER BY fecha_atencion DESC;
```

#### **Connection Pooling Enterprise**
```python
# ConfiguraciÃ³n production-ready
DATABASE_CONFIG = {
    "host": os.getenv("DB_HOST"),
    "port": 5432,
    "database": os.getenv("DB_NAME"),
    # Connection pooling optimizado
    "min_connections": 5,
    "max_connections": 20,
    "max_connection_age": 300,  # 5 minutos
    "max_queries": 50000,
    
    # Performance tuning
    "command_timeout": 60,
    "server_prepared_statement_cache_size": 100,
    
    # SSL y Security
    "ssl": "require",
    "sslmode": "verify-full"
}

# Pool management con health checks
async def get_db_connection():
    """Connection con retry automÃ¡tico y health check"""
    for attempt in range(3):
        try:
            conn = await asyncpg.connect(**DATABASE_CONFIG)
            # Health check bÃ¡sico
            await conn.fetchval("SELECT 1")
            return conn
        except Exception as e:
            if attempt == 2:  # Ãšltimo intento
                logger.error(f"DB connection failed: {e}")
                raise
            await asyncio.sleep(2 ** attempt)  # Exponential backoff
```

### **ðŸ“ˆ Monitoring y Alertas AutomÃ¡ticas**
```python
# MÃ©tricas automÃ¡ticas de performance
class DatabaseMetrics:
    def __init__(self):
        self.connection_pool_usage = Histogram('db_connection_pool_usage')
        self.query_duration = Histogram('db_query_duration_seconds') 
        self.slow_query_count = Counter('db_slow_queries_total')
        
    async def track_query_performance(self, query_func):
        start_time = time.time()
        try:
            result = await query_func()
            duration = time.time() - start_time
            
            self.query_duration.observe(duration)
            
            # Alerta queries lentas
            if duration > 1.0:  # > 1 segundo
                self.slow_query_count.inc()
                logger.warning(f"Slow query detected: {duration:.2f}s")
                
            return result
        except Exception as e:
            logger.error(f"Query failed: {e}")
            raise
```

---

## ðŸ”„ **MIGRATION STRATEGIES AVANZADAS**

### **ðŸ“‹ Migration Workflow Enterprise**

#### **1. ðŸŽ¯ Migrations con Zero Downtime**
```sql
-- TÃ©cnica: Backward-compatible changes primero
-- FASE 1: Agregar nueva columna (NULLABLE)
ALTER TABLE atencion_infancia 
ADD COLUMN nuevo_campo_calculado DECIMAL(10,2);

-- FASE 2: FunciÃ³n para calcular valores (idempotente)
CREATE OR REPLACE FUNCTION calcular_nuevo_campo(atencion_id UUID)
RETURNS DECIMAL(10,2) AS $$
BEGIN
    -- LÃ³gica cÃ¡lculo compleja
    RETURN (
        SELECT peso_kg / ((talla_cm / 100.0) ^ 2)
        FROM atencion_infancia 
        WHERE id = atencion_id
    );
END;
$$ LANGUAGE plpgsql;

-- FASE 3: Poblar datos existentes (por lotes)
DO $$ 
DECLARE
    batch_size INTEGER := 1000;
    offset_val INTEGER := 0;
    affected_rows INTEGER;
BEGIN
    LOOP
        UPDATE atencion_infancia 
        SET nuevo_campo_calculado = calcular_nuevo_campo(id)
        WHERE id IN (
            SELECT id FROM atencion_infancia 
            WHERE nuevo_campo_calculado IS NULL
            LIMIT batch_size OFFSET offset_val
        );
        
        GET DIAGNOSTICS affected_rows = ROW_COUNT;
        offset_val := offset_val + batch_size;
        
        EXIT WHEN affected_rows = 0;
        
        -- Pausa para no bloquear producciÃ³n
        PERFORM pg_sleep(0.1);
    END LOOP;
END $$;

-- FASE 4: Hacer NOT NULL despuÃ©s de poblar
ALTER TABLE atencion_infancia 
ALTER COLUMN nuevo_campo_calculado SET NOT NULL;
```

#### **2. ðŸ”„ Rollback Strategy AutomÃ¡tico**
```python
# Migration con rollback automÃ¡tico
class MigrationWithRollback:
    def __init__(self, db_connection):
        self.db = db_connection
        self.rollback_actions = []
        
    async def add_column_safe(self, table, column, definition):
        try:
            # Forward migration
            await self.db.execute(f"ALTER TABLE {table} ADD COLUMN {column} {definition}")
            
            # Registrar rollback action
            self.rollback_actions.append(f"ALTER TABLE {table} DROP COLUMN {column}")
            
        except Exception as e:
            await self.execute_rollback()
            raise MigrationException(f"Failed to add column: {e}")
    
    async def execute_rollback(self):
        """Ejecutar rollback en orden reverso"""
        for action in reversed(self.rollback_actions):
            try:
                await self.db.execute(action)
                logger.info(f"Rollback executed: {action}")
            except Exception as e:
                logger.error(f"Rollback failed: {action} - {e}")
```

### **ðŸ“Š Migration Testing AutomÃ¡tico**
```python
# Tests automÃ¡ticos para migrations
class MigrationTests:
    def test_migration_performance(self):
        """Test que migration no degrada performance"""
        # Benchmark pre-migration
        pre_time = self.benchmark_critical_queries()
        
        # Ejecutar migration
        self.run_migration()
        
        # Benchmark post-migration  
        post_time = self.benchmark_critical_queries()
        
        # Assertion: No degradaciÃ³n > 20%
        assert post_time <= pre_time * 1.2, "Migration degraded performance"
        
    def test_migration_data_integrity(self):
        """Test integridad datos post-migration"""
        # Counts pre-migration
        pre_counts = self.get_table_counts()
        
        # Ejecutar migration
        self.run_migration()
        
        # Verificar counts post-migration
        post_counts = self.get_table_counts()
        assert pre_counts == post_counts, "Data loss detected"
        
        # Verificar constraints
        constraint_violations = self.check_constraint_violations()
        assert len(constraint_violations) == 0, f"Constraints violated: {constraint_violations}"
```

---

## ðŸ›ï¸ **GOBERNANZA DE DATOS NORMATIVOS** â­â­

### **ðŸ“‹ Framework "Datos Normativos como CÃ³digo"**

#### **ðŸ”’ Versionado AutomÃ¡tico Cambios Normativos**
```python
# Sistema de versionado para cambios regulatorios
class NormativeDataGovernance:
    def __init__(self):
        self.current_version = "resolucion_3280_2018_v1.0"
        self.audit_logger = NormativeAuditLogger()
        
    def apply_normative_change(self, change_spec: NormativeChange):
        """
        Aplicar cambio normativo con trazabilidad completa
        """
        try:
            # 1. Validar change spec contra esquema
            self.validate_change_spec(change_spec)
            
            # 2. Crear version nueva
            new_version = self.create_version_tag(change_spec)
            
            # 3. Generar migration automÃ¡tica
            migration = self.generate_migration_from_spec(change_spec)
            
            # 4. Ejecutar con rollback preparado
            self.execute_migration_safe(migration, new_version)
            
            # 5. Auditar cambio completo
            self.audit_logger.log_normative_change(
                from_version=self.current_version,
                to_version=new_version,
                change_spec=change_spec,
                applied_at=datetime.now(),
                applied_by=self.get_current_user()
            )
            
            self.current_version = new_version
            
        except Exception as e:
            self.audit_logger.log_normative_failure(change_spec, e)
            raise NormativeComplianceException(f"Failed to apply normative change: {e}")

# Ejemplo change spec
normative_change = NormativeChange(
    regulation="resolucion_3280_2018",
    article="3.3.2",  # Infancia
    change_type="field_added",
    description="Agregar campo tamizaje_salud_mental obligatorio",
    fields_added=[
        {
            "name": "tamizaje_salud_mental",
            "type": "resultado_tamizaje",
            "required": True,
            "validation": "Must be NORMAL, ALTERADO, or REQUIERE_EVALUACION"
        }
    ],
    effective_date="2025-01-01",
    migration_strategy="backward_compatible"
)
```

#### **ðŸ” AuditorÃ­a Compliance AutomÃ¡tica**
```sql
-- Sistema auditorÃ­a compliance automÃ¡tico
CREATE TABLE normative_compliance_audit (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    regulation_reference TEXT NOT NULL,  -- ej: "resolucion_3280_art_3.3.2"
    table_name TEXT NOT NULL,
    field_name TEXT NOT NULL,
    compliance_rule TEXT NOT NULL,
    
    -- Resultados auditorÃ­a
    total_records INTEGER,
    compliant_records INTEGER,
    non_compliant_records INTEGER,
    compliance_percentage DECIMAL(5,2),
    
    -- Ejemplos no compliance (para correcciÃ³n)
    sample_violations JSONB,
    
    audit_timestamp TIMESTAMPTZ DEFAULT now(),
    audit_status TEXT CHECK (audit_status IN ('PASS', 'FAIL', 'WARNING'))
);

-- FunciÃ³n auditorÃ­a automÃ¡tica
CREATE OR REPLACE FUNCTION audit_compliance_resolucion_3280()
RETURNS TABLE(audit_result JSON) AS $$
DECLARE
    audit_record RECORD;
BEGIN
    -- Auditar campo obligatorio: peso_kg en infancia
    INSERT INTO normative_compliance_audit (
        regulation_reference,
        table_name,
        field_name,
        compliance_rule,
        total_records,
        compliant_records,
        non_compliant_records,
        compliance_percentage,
        audit_status
    )
    SELECT 
        'resolucion_3280_art_3.3.2',
        'atencion_infancia',
        'peso_kg', 
        'peso_kg IS NOT NULL AND peso_kg > 0 AND peso_kg <= 150',
        COUNT(*),
        COUNT(*) FILTER (WHERE peso_kg IS NOT NULL AND peso_kg > 0 AND peso_kg <= 150),
        COUNT(*) FILTER (WHERE peso_kg IS NULL OR peso_kg <= 0 OR peso_kg > 150),
        (COUNT(*) FILTER (WHERE peso_kg IS NOT NULL AND peso_kg > 0 AND peso_kg <= 150) * 100.0 / COUNT(*)),
        CASE 
            WHEN (COUNT(*) FILTER (WHERE peso_kg IS NOT NULL AND peso_kg > 0 AND peso_kg <= 150) * 100.0 / COUNT(*)) = 100 
            THEN 'PASS'
            WHEN (COUNT(*) FILTER (WHERE peso_kg IS NOT NULL AND peso_kg > 0 AND peso_kg <= 150) * 100.0 / COUNT(*)) >= 95 
            THEN 'WARNING'
            ELSE 'FAIL'
        END
    FROM atencion_infancia;
    
    -- Retornar resultados
    RETURN QUERY 
    SELECT row_to_json(nca) FROM normative_compliance_audit nca 
    WHERE nca.audit_timestamp >= now() - INTERVAL '1 minute';
END;
$$ LANGUAGE plpgsql;
```

---

## ðŸ”— **Referencias TÃ©cnicas**

- **[Architectural Patterns](./architectural-patterns.md)** - Contexto polimorfismo
- **[Operations Monitoring](./operations-monitoring.md)** - MÃ©tricas database performance
- **[Security Compliance](./security-compliance.md)** - Gobernanza datos sensibles
- **[ResoluciÃ³n 3280 RPMS](../02-regulations/resolucion-3280-rpms.md)** - Requerimientos normativos especÃ­ficos

---

*ðŸ’¾ Estrategia validada en producciÃ³n. MÃ©tricas reales: 0 pÃ©rdidas de datos, 95%+ compliance automÃ¡tico, <50ms query promedio.*